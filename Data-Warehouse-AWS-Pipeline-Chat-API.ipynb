{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pipeline de Dados do Telegram\n\n[Rafael Barbosa](https://www.linkedin.com/in/barbosa89/)\n<br>\n[André Perez](https://www.linkedin.com/in/andremarcosperez/)\n<br>\n[Mariane Neiva](https://www.linkedin.com/in/mariane-neiva/)\n\n\n---\n\nA seguir um modelo de pipeline com guia de configuração utilizando Amazon Web Services, Python e SQL para ingerir, extrair, transformar e carregar dados de mensagens de um chat do Telegram, seguindo o modelo da imagem a seguir.\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/Telegram%20Data%20Pipeline%20Schema.png?raw=true)\n\nInsights importantes são inferidos a partir dos dados de mensagens de chats, identificando gargalos mais comuns e áreas para melhoria, guiando o desempenho de agentes, promovendo ofertas personalizadas, gerando leads de forma eficiente, identificando tendências e entendendo necessidades dos clientes, avaliando a satisfação do cliente, e claro melhorando a comunicação e colaboração entre equipes.\n\nEste passo a passo processa dados transacionais (o que acontece), em dados analíticos (por que e como acontece) e deve ter seus parâmetros configurados.","metadata":{}},{"cell_type":"markdown","source":"\n## 0/3\\. Fonte de Dados\n\nDados de mensagens captadas por um [**Telegram bot**](https://core.telegram.org/bots/api) via `API token` disponibilizado no `BotFather` do Telegram. [Crie e configure um Telegram bot API token aqui.](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/Pipeline-Data-API-Telegram-bot-Profissao_Analista_de_dados_M42_Exercicio_pt1_Rafael_Barbosa.ipynb) Guarde o \"token\" em \"base_url\" usando a célula de código Python abaixo.","metadata":{}},{"cell_type":"code","source":"### Salva o API token em url_base\n# A `url` base é comum a todos os métodos da API\nfrom getpass import getpass\nimport requests\n\nprint(\"insert Telegram bot API Token\")\ntoken = getpass()\n\nbase_url = f'https://api.telegram.org/bot{token}'\nprint(\"base_url stored\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:16:45.234185Z","iopub.execute_input":"2024-05-02T17:16:45.234618Z","iopub.status.idle":"2024-05-02T17:16:49.171986Z","shell.execute_reply.started":"2024-05-02T17:16:45.234587Z","shell.execute_reply":"2024-05-02T17:16:49.170755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### `getMe` retorna informações sobre o bot\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/getMe')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:16:53.828070Z","iopub.execute_input":"2024-05-02T17:16:53.828549Z","iopub.status.idle":"2024-05-02T17:16:53.887686Z","shell.execute_reply.started":"2024-05-02T17:16:53.828513Z","shell.execute_reply":"2024-05-02T17:16:53.886566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### `getUpdates` revela a estrutura de dados de mensagens captadas pelo bot\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/getUpdates')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:17:52.147457Z","iopub.execute_input":"2024-05-02T17:17:52.147851Z","iopub.status.idle":"2024-05-02T17:17:52.218270Z","shell.execute_reply.started":"2024-05-02T17:17:52.147822Z","shell.execute_reply":"2024-05-02T17:17:52.217068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.1. Guarde o número encontrado no 'id' do item 'chat' do `getUpdates` para configurar a variável de ambiente do `AWS Lambda`.","metadata":{}},{"cell_type":"markdown","source":"# 1/3. Ingestão\n\n**1.1.** `AWS S3 bucket` com sufixo `-raw` para **dados crus**;\n\n**1.2.** `AWS Lambda` **função Python** que recebe e armazena dados crus no formato JSON, no `AWS S3 bucket` sufixo `-raw`;\n\n1.2.1. variáveis de ambiente para **nome do bucket de dados crus** (AWS_S3_BUCKET) e para **id do chat do Telegram** (TELEGRAM_CHAT_ID) em \"Configuração > Variáveis de Ambiente > Editar\" no painel da função;\n\n1.2.2. permissão para escrita no bucket de dados crus em \"Configuração > Permissôes > Nome da Função [<Função>]\" no painel da função e no `AWS IAM` \"Adicionar permissões > Anexar políticas\" para o `AWS S3 bucket` sufixo `-raw`;\n\n\n```python\n### código Python da função `AWS Lambda` criada para dados crus:\n\n# persistir as mensagens captadas pelo bot do Telegram em um bucket do AWS S3\n# Recebe a mensagem no parâmetro event;\n# Verifica se a mensagem tem origem no grupo do Telegram correto;\n# Persiste a mensagem no formato JSON no bucket do AWS S3;\n# Retorna uma mensagem de sucesso (código de retorno HTTP igual a 200) a API de bots do Telegram.\n\nimport os\nimport json\nimport logging\nfrom datetime import datetime, timezone, timedelta\n\nimport boto3\n\n\ndef lambda_handler(event: dict, context: dict) -> dict:\n\n  '''\n  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n  seu conteúdo se foi produzida em um determinado grupo e a escreve, \n  em seu formato original JSON, em um bucket do AWS S3.\n  '''\n\n  # vars de ambiente\n\n  BUCKET = os.environ['AWS_S3_BUCKET']\n  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n\n  # vars lógicas\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n  filename = f'{timestamp}.json'\n\n  # código principal\n\n  client = boto3.client('s3')\n\n  try:\n\n    message = json.loads(event[\"body\"])\n    chat_id = message[\"message\"][\"chat\"][\"id\"]\n\n    if chat_id == TELEGRAM_CHAT_ID:\n\n      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n        json.dump(message, fp)\n\n      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n\n  except Exception as exc:\n      logging.error(msg=exc)\n      return dict(statusCode=\"500\")\n\n  else:\n      return dict(statusCode=\"200\")\n```\n\n**1.3.** `AWS API Gateway` **API REST** com sufixo `-api` para acionar a função `AWS Lambda` criada para receber e armazenar dados crus do `Telegram bot API` no `AWS S3 bucket` sufixo `-raw`;\n\n1.3.1. Criar método tipo \"POST\", integração \"Função do Lambda\", \"Integração do proxy do Lambda\" ativa, escolher a função do `AWS Lambda` criada;\n\n1.3.2. Implantar API, Estágio \"Novo estágio\", Nome do estágio \"dev\", guardar \"Invocar URL\" em \"aws_api_gateway_url\" usando a célula de código Python abaixo;\n\n> Nota: não disponibilize o endereço da API gerada.\n\n**1.4.** `setWebhook` via `Telegram bot API` para redirecionar as informações de mensagens captadas pelo bot para o endereço \"aws_api_gateway_url\" usando a célula de código Python abaixo;\n\n> Nota: não disponibilize o token da API de bots do Telegram.","metadata":{}},{"cell_type":"code","source":"### guarda \"Invocar URL\" em \"aws_api_gateway_url\"\n\nfrom getpass import getpass\n\nprint(\"Insert AWS API Gateway Invoke URL\")\naws_api_gateway_url = getpass()\nprint(\"aws_api_gateway_url stored\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:17:09.434686Z","iopub.execute_input":"2024-05-02T17:17:09.435147Z","iopub.status.idle":"2024-05-02T17:17:12.195881Z","shell.execute_reply.started":"2024-05-02T17:17:09.435083Z","shell.execute_reply":"2024-05-02T17:17:12.194439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### configura o webhook para redirecionar as mensagens para a url do AWS API Gateway\n\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:18:17.343974Z","iopub.execute_input":"2024-05-02T17:18:17.344590Z","iopub.status.idle":"2024-05-02T17:18:17.389784Z","shell.execute_reply.started":"2024-05-02T17:18:17.344419Z","shell.execute_reply":"2024-05-02T17:18:17.388370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### este trecho apaga e redefine o Webhook\n# import json\n# import requests\n\n# requests.get(url=f'{base_url}/deleteWebhook')\n# print(\"Webhook reseted\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### getWebhookInfo retorna as informações sobre o webhook configurado\n\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/getWebhookInfo')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:18:25.206192Z","iopub.execute_input":"2024-05-02T17:18:25.206600Z","iopub.status.idle":"2024-05-02T17:18:25.260798Z","shell.execute_reply.started":"2024-05-02T17:18:25.206570Z","shell.execute_reply":"2024-05-02T17:18:25.259698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2/3\\. ETL\n\n**2.1.** `AWS S3 bucket` com o sufixo `-enriched` para armazenar **dados enriquecidos**;\n\n**2.2.** `AWS Lambda` **função Python** que transforma o JSON do dia anterior (D-1) do bucket sufixo `-raw` e salva em um arquivo PARQUET particionado por dia no bucket sufixo `-enriched`;\n\n2.2.1. variáveis de ambiente para **nome do bucket de dados crus** (AWS_S3_BUCKET) e **nome do bucket de dados enriquecidos** (AWS_S3_ENRICHED) em \"Configuração > Variáveis de Ambiente > Editar\" no painel da função;\n\n2.2.2. permissão para escrita no bucket de dados enriquecidos em \"Configuração > Permissôes > Nome da Função [<Função>]\" no painel da função e no `AWS IAM` \"Adicionar permissões > Anexar políticas\" para o `AWS S3 bucket` sufixo `-enriched`;\n\n2.2.3. tempo limite para 5 minutos em \"Configuração > Configuração geral > Editar\" no painel da função;\n\n2.2.4. camada Python PyArrow em \"Código > Camadas > Adicionar uma camada > criar uma nova camada > Fazer upload de um arquivo do Amazon S3 ([carregar arquivo para Python compatível](https://github.com/awslabs/aws-data-wrangler/releases) em um `AWS S3 bucket` exclusivo) > inserir Link do URL do Amazon S3 > Tempos de execução compatíveis > Camadas personalizadas > Escolher > Versão 1 > Adicionar\" no painel da função;\n\n```python\n### código Python da função `AWS Lambda` criada para dados enriquecidos:\n\n# Lista todos os arquivos JSON de uma única participação da camada crua de um bucket do AWS S3;\n# Para cada arquivo listado:\n# Faz o download do arquivo e carrega o conteúdo da mensagem;\n# Executa uma função de data wrangling;\n# Cria uma tabela do PyArrow e a contatena com as demais.\n# Persiste a tabela no formato Parquet na camada enriquecida em um bucket do AWS S3\n\nimport os\nimport json\nimport logging\nfrom datetime import datetime, timedelta, timezone\n\nimport boto3\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\n\ndef lambda_handler(event: dict, context: dict) -> bool:\n\n  '''\n  Diariamente é executado para compactar as diversas mensagensm, no formato\n  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único \n  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n  '''\n\n  # vars de ambiente\n\n  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n\n  # vars lógicas\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n  # código principal\n\n  table = None\n  client = boto3.client('s3')\n\n  try:\n\n      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n\n      for content in response['Contents']:\n\n        key = content['Key']\n        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n\n        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n\n          data = json.load(fp)\n          data = data[\"message\"]\n\n        parsed_data = parse_data(data=data)\n        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n\n        if table:\n\n          table = pa.concat_tables([table, iter_table])\n\n        else:\n\n          table = iter_table\n          iter_table = None\n          \n      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n\n      return True\n  \n  except Exception as exc:\n      logging.error(msg=exc)\n      return False\n    \n\n# data wrangling\n\ndef parse_data(data: dict) -> dict:\n\n  date = datetime.now().strftime('%Y-%m-%d')\n  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n  parsed_data = dict()\n\n  for key, value in data.items():\n\n      if key == 'from':\n          for k, v in data[key].items():\n              if k in ['id', 'is_bot', 'first_name']:\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n      elif key == 'chat':\n          for k, v in data[key].items():\n              if k in ['id', 'type']:\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n      elif key in ['message_id', 'date', 'text']:\n          parsed_data[key] = [value]\n\n  if not 'text' in parsed_data.keys():\n    parsed_data['text'] = [None]\n\n  return parsed_data\n```\n\n**2.3.** `AWS EventBridge` para acionar a função `AWS Lambda` criada para transformar o JSON do dia anterior e armazenar o PARQUET no `AWS S3 bucket` sufixo `-enriched` todos os dias 00h (GMT-3) em \"Criar regra > Nome, Programação > Continuar a criar regra > cron(0 3 * * ? *) > Próximo > Serviço AWS, Função do Lambda, Função (sufixo `-enriched`) > Próximo (x2) > Criar regra\";","metadata":{}},{"cell_type":"markdown","source":"## 3/3\\. Apresentação\n\n**3.1.** Tabela com os dados enriquecidos utilizando SQL no `AWS Athena`;\n\n```sql\n# Consulta SQL para criar tabela com os dados enriqeucidos particionados por dia:\n\nCREATE EXTERNAL TABLE `telegram`(\n  `message_id` bigint, \n  `user_id` bigint, \n  `user_is_bot` boolean, \n  `user_first_name` string, \n  `chat_id` bigint, \n  `chat_type` string, \n  `text` string, \n  `date` bigint)\nPARTITIONED BY ( \n  `context_date` date)\nROW FORMAT SERDE \n  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' \nSTORED AS INPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat' \nOUTPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\nLOCATION\n  's3://<bucket-enriquecido>/<pasta-particionada>'\n```\n\n![](https://github.com/rafie-b/data-analytics/blob/main/M42%20images/athena-create-table.png?raw=true)\n\n**3.2.** Carrega as partições na tabela criada;\n\n```sql\nMSCK REPAIR TABLE `telegram`;\n```\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/athena-repair-table.png?raw=true)\n\n3.2.1. Para atualizar a tabela também é possível utilizar o comando a seguir para reduzir possíveis custos de consulta;\n ```sql\n ALTER TABLE <nome-tabela> ADD PARTITION <coluna-partição> = <valor-partição>\n  ```\n\n**3.3.** Dados analíticos;\n\n- Quantidade de mensagens por dia;\n\n```sql\nSELECT \n  context_date, \n  count(1) AS \"message_amount\" \nFROM \"telegram\" \nGROUP BY context_date \nORDER BY context_date DESC\n```\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/athena-select-message_amount.png?raw=true)\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/graph-select-message_amount.png?raw=true)\n\n- Quantidade de mensagens por usuário por dia.\n\n```sql\nSELECT \n  user_id, \n  user_first_name, \n  context_date, \n  count(1) AS \"message_amount\" \nFROM \"telegram\" \nGROUP BY \n  user_id, \n  user_first_name, \n  context_date \nORDER BY context_date DESC\n```\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/athena-select-user-message_amount.png?raw=true)\n\n- Média do tamanho das mensagens por usuário por dia.\n\n```sql\nSELECT \n  user_id, \n  user_first_name, \n  context_date,\n  CAST(AVG(length(text)) AS INT) AS \"average_message_length\" \nFROM \"telegram\" \nGROUP BY \n  user_id, \n  user_first_name, \n  context_date \nORDER BY context_date DESC\n```\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/athena-select-user-message_lenght.png?raw=true)\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/graph-select-user-message_lenght.png?raw=true)\n\n- Quantidade de mensagens por hora por dia da semana por número da semana.\n\n```sql\nWITH \nparsed_date_cte AS (\n    SELECT \n        *, \n        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n    FROM \"telegram\" \n),\nhour_week_cte AS (\n    SELECT\n        *,\n        EXTRACT(hour FROM parsed_date) AS parsed_date_hour,\n        EXTRACT(dow FROM parsed_date) AS parsed_date_weekday,\n        EXTRACT(week FROM parsed_date) AS parsed_date_weeknum\n    FROM parsed_date_cte\n)\nSELECT\n    parsed_date_hour,\n    parsed_date_weekday,\n    parsed_date_weeknum,\n    count(1) AS \"message_amount\" \nFROM hour_week_cte\nGROUP BY\n    parsed_date_hour,\n    parsed_date_weekday,\n    parsed_date_weeknum\nORDER BY\n    parsed_date_weeknum,\n    parsed_date_weekday\n```\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/athena-select-hour-week-message_amount.png?raw=true)\n\n-  Total de vezes que cada palavra única aparece em todas as mensagens\n\n```sql\nWITH words AS (\n  SELECT word\n  FROM \"telegram\",\n  UNNEST(split(\"text\", ' ')) AS t(word)\n)\nSELECT word, COUNT(*) as count\nFROM words\nGROUP BY word\nORDER BY count DESC;\n```\n\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/athena-select-count-unnest-words.png?raw=true)\n![](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/M42%20images/graph-select-count-unnest-words.png?raw=true)","metadata":{}}]}