{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pipeline e Análise de Dados de Mensagens do Telegram\n\n[Rafael Barbosa](https://www.linkedin.com/in/barbosa89/)\n<br>\n[André Perez](https://www.linkedin.com/in/andremarcosperez/)\n<br>\n[Mariane Neiva](https://www.linkedin.com/in/mariane-neiva/)\n\n\n---\n\nA seguir um modelo de pipeline com guia de configuração utilizando Amazon Web Services, Python e SQL para ingerir, extrair, transformar e carregar dados de mensagens de um chat do Telegram, seguindo o modelo da imagem a seguir.\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/Telegram%20Data%20Pipeline%20Schema.png?raw=true)\n\nInsights importantes são inferidos a partir dos dados de mensagens de chats, identificando gargalos mais comuns e áreas para melhoria, guiando o desempenho de agentes, promovendo ofertas personalizadas, gerando leads de forma eficiente, identificando tendências e entendendo necessidades dos clientes, avaliando a satisfação do cliente, e claro melhorando a comunicação e colaboração entre equipes.\n\nEste passo a passo processa dados transacionais (o que acontece), em dados analíticos (por que e como acontece) e deve ter seus parâmetros configurados.","metadata":{}},{"cell_type":"markdown","source":"\n## 0/3\\. Fonte de Dados\n\nDados de mensagens captadas por um [**Telegram bot**](https://core.telegram.org/bots/api) via `API token` disponibilizado no `BotFather` do Telegram. [Crie e configure um Telegram bot API token aqui.](https://github.com/rafie-b/Profession-Data-Analyst/blob/main/Pipeline-Data-API-Telegram-bot-Profissao_Analista_de_dados_M42_Exercicio_pt1_Rafael_Barbosa.ipynb) Guarde o \"token\" em \"base_url\" usando a célula de código Python abaixo.","metadata":{}},{"cell_type":"code","source":"### Salva o API token em url_base\n# A `url` base é comum a todos os métodos da API\nfrom getpass import getpass\nimport requests\n\nprint(\"insert Telegram bot API Token\")\ntoken = getpass()\n\nbase_url = f'https://api.telegram.org/bot{token}'\nprint(\"base_url stored\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T23:31:47.432841Z","iopub.execute_input":"2024-06-09T23:31:47.433255Z","iopub.status.idle":"2024-06-09T23:31:50.900257Z","shell.execute_reply.started":"2024-06-09T23:31:47.433220Z","shell.execute_reply":"2024-06-09T23:31:50.899148Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"insert Telegram bot API Token\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" ··············································\n"},{"name":"stdout","text":"base_url stored\n","output_type":"stream"}]},{"cell_type":"code","source":"### `getMe` retorna informações sobre o bot\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/getMe')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T23:36:15.965605Z","iopub.execute_input":"2024-06-09T23:36:15.965983Z","iopub.status.idle":"2024-06-09T23:36:16.708108Z","shell.execute_reply.started":"2024-06-09T23:36:15.965955Z","shell.execute_reply":"2024-06-09T23:36:16.706874Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{\n  \"ok\": true,\n  \"result\": {\n    \"id\": 7084060512,\n    \"is_bot\": true,\n    \"first_name\": \"ebac_m42_bot\",\n    \"username\": \"ebacm42_bot\",\n    \"can_join_groups\": false,\n    \"can_read_all_group_messages\": false,\n    \"supports_inline_queries\": false,\n    \"can_connect_to_business\": false\n  }\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"### `getUpdates` revela a estrutura de dados de mensagens captadas pelo bot\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/getUpdates')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T23:36:39.789999Z","iopub.execute_input":"2024-06-09T23:36:39.790433Z","iopub.status.idle":"2024-06-09T23:36:40.549091Z","shell.execute_reply.started":"2024-06-09T23:36:39.790399Z","shell.execute_reply":"2024-06-09T23:36:40.547879Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{\n  \"ok\": true,\n  \"result\": [\n    {\n      \"update_id\": 827865390,\n      \"message\": {\n        \"message_id\": 68,\n        \"from\": {\n          \"id\": 7162819601,\n          \"is_bot\": false,\n          \"first_name\": \"Rafie\",\n          \"language_code\": \"en\"\n        },\n        \"chat\": {\n          \"id\": -1001993072220,\n          \"title\": \"EBAC M42 BOT\",\n          \"type\": \"supergroup\"\n        },\n        \"date\": 1717976196,\n        \"text\": \"up up\"\n      }\n    }\n  ]\n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"0.1. Guarde o número encontrado no 'id' do item 'chat' do `getUpdates` para configurar a variável de ambiente do `AWS Lambda`.","metadata":{}},{"cell_type":"markdown","source":"# 1/3. Ingestão\n\n**1.1.** `AWS S3 bucket` com sufixo `-raw` para **dados crus**;\n\n**1.2.** `AWS Lambda` **função Python** que recebe e armazena dados crus no formato JSON, no `AWS S3 bucket` sufixo `-raw`;\n\n1.2.1. variáveis de ambiente para **nome do bucket de dados crus** (AWS_S3_BUCKET) e para **id do chat do Telegram** (TELEGRAM_CHAT_ID) em \"Configuração > Variáveis de Ambiente > Editar\" no painel da função;\n\n1.2.2. permissão para escrita no bucket de dados crus em \"Configuração > Permissôes > Nome da Função [<Função>]\" no painel da função e no `AWS IAM` \"Adicionar permissões > Anexar políticas\" para o `AWS S3 bucket` sufixo `-raw`;\n\n\n```python\n### código Python da função `AWS Lambda` criada para dados crus:\n\n# persistir as mensagens captadas pelo bot do Telegram em um bucket do AWS S3\n# Recebe a mensagem no parâmetro event;\n# Verifica se a mensagem tem origem no grupo do Telegram correto;\n# Persiste a mensagem no formato JSON no bucket do AWS S3;\n# Retorna uma mensagem de sucesso (código de retorno HTTP igual a 200) a API de bots do Telegram.\n\nimport os\nimport json\nimport logging\nfrom datetime import datetime, timezone, timedelta\n\nimport boto3\n\n\ndef lambda_handler(event: dict, context: dict) -> dict:\n\n  '''\n  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n  seu conteúdo se foi produzida em um determinado grupo e a escreve, \n  em seu formato original JSON, em um bucket do AWS S3.\n  '''\n\n  # vars de ambiente\n\n  BUCKET = os.environ['AWS_S3_BUCKET']\n  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n\n  # vars lógicas\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n  filename = f'{timestamp}.json'\n\n  # código principal\n\n  client = boto3.client('s3')\n\n  try:\n\n    message = json.loads(event[\"body\"])\n    chat_id = message[\"message\"][\"chat\"][\"id\"]\n\n    if chat_id == TELEGRAM_CHAT_ID:\n\n      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n        json.dump(message, fp)\n\n      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n\n  except Exception as exc:\n      logging.error(msg=exc)\n      return dict(statusCode=\"500\")\n\n  else:\n      return dict(statusCode=\"200\")\n```\n\n**1.3.** `AWS API Gateway` **API REST** com sufixo `-api` para acionar a função `AWS Lambda` criada para receber e armazenar dados crus do `Telegram bot API` no `AWS S3 bucket` sufixo `-raw`;\n\n1.3.1. Criar método tipo \"POST\", integração \"Função do Lambda\", \"Integração do proxy do Lambda\" ativa, escolher a função do `AWS Lambda` criada;\n\n1.3.2. Implantar API, Estágio \"Novo estágio\", Nome do estágio \"dev\", guardar \"Invocar URL\" em \"aws_api_gateway_url\" usando a célula de código Python abaixo;\n\n> Nota: não disponibilize o endereço da API gerada.\n\n**1.4.** `setWebhook` via `Telegram bot API` para redirecionar as informações de mensagens captadas pelo bot para o endereço \"aws_api_gateway_url\" usando a célula de código Python abaixo;\n\n> Nota: não disponibilize o token da API de bots do Telegram.","metadata":{}},{"cell_type":"code","source":"### guarda \"Invocar URL\" em \"aws_api_gateway_url\"\n\nfrom getpass import getpass\n\nprint(\"Insert AWS API Gateway Invoke URL\")\naws_api_gateway_url = getpass()\nprint(\"aws_api_gateway_url stored\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T23:35:17.739987Z","iopub.execute_input":"2024-06-09T23:35:17.740394Z","iopub.status.idle":"2024-06-09T23:35:20.654150Z","shell.execute_reply.started":"2024-06-09T23:35:17.740363Z","shell.execute_reply":"2024-06-09T23:35:20.652934Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Insert AWS API Gateway Invoke URL\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" ··························································\n"},{"name":"stdout","text":"aws_api_gateway_url stored\n","output_type":"stream"}]},{"cell_type":"code","source":"### configura o webhook para redirecionar as mensagens para a url do AWS API Gateway\n\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T23:36:52.993717Z","iopub.execute_input":"2024-06-09T23:36:52.994093Z","iopub.status.idle":"2024-06-09T23:36:53.759316Z","shell.execute_reply.started":"2024-06-09T23:36:52.994062Z","shell.execute_reply":"2024-06-09T23:36:53.757968Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{\n  \"ok\": true,\n  \"result\": true,\n  \"description\": \"Webhook was set\"\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"# ### este trecho apaga e redefine o Webhook\n# import json\n# import requests\n\n# requests.get(url=f'{base_url}/deleteWebhook')\n# print(\"Webhook reseted\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### getWebhookInfo retorna as informações sobre o webhook configurado\n\nimport json\nimport requests\n\nresponse = requests.get(url=f'{base_url}/getWebhookInfo')\nprint(json.dumps(json.loads(response.text), indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T23:36:58.432775Z","iopub.execute_input":"2024-06-09T23:36:58.433157Z","iopub.status.idle":"2024-06-09T23:36:59.189671Z","shell.execute_reply.started":"2024-06-09T23:36:58.433122Z","shell.execute_reply":"2024-06-09T23:36:59.188348Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{\n  \"ok\": true,\n  \"result\": {\n    \"url\": \"https://hppmtvbty7.execute-api.sa-east-1.amazonaws.com/dev\",\n    \"has_custom_certificate\": false,\n    \"pending_update_count\": 0,\n    \"max_connections\": 40,\n    \"ip_address\": \"54.233.185.14\"\n  }\n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2/3\\. ETL\n\n**2.1.** `AWS S3 bucket` com o sufixo `-enriched` para armazenar **dados enriquecidos**;\n\n**2.2.** `AWS Lambda` **função Python** que transforma o JSON do dia anterior (D-1) do bucket sufixo `-raw` e salva em um arquivo PARQUET particionado por dia no bucket sufixo `-enriched`;\n\n2.2.1. variáveis de ambiente para **nome do bucket de dados crus** (AWS_S3_BUCKET) e **nome do bucket de dados enriquecidos** (AWS_S3_ENRICHED) em \"Configuração > Variáveis de Ambiente > Editar\" no painel da função;\n\n2.2.2. permissão para escrita no bucket de dados enriquecidos em \"Configuração > Permissôes > Nome da Função [<Função>]\" no painel da função e no `AWS IAM` \"Adicionar permissões > Anexar políticas\" para o `AWS S3 bucket` sufixo `-enriched`;\n\n2.2.3. tempo limite para 5 minutos em \"Configuração > Configuração geral > Editar\" no painel da função;\n\n2.2.4. camada Python PyArrow em \"Código > Camadas > Adicionar uma camada > criar uma nova camada > Fazer upload de um arquivo do Amazon S3 ([carregar arquivo para Python compatível](https://github.com/awslabs/aws-data-wrangler/releases) em um `AWS S3 bucket` exclusivo) > inserir Link do URL do Amazon S3 > Tempos de execução compatíveis > Camadas personalizadas > Escolher > Versão 1 > Adicionar\" no painel da função;\n\n```python\n### código Python da função `AWS Lambda` criada para dados enriquecidos:\n\n# Lista todos os arquivos JSON de uma única participação da camada crua de um bucket do AWS S3;\n# Para cada arquivo listado:\n# Faz o download do arquivo e carrega o conteúdo da mensagem;\n# Executa uma função de data wrangling;\n# Cria uma tabela do PyArrow e a contatena com as demais.\n# Persiste a tabela no formato Parquet na camada enriquecida em um bucket do AWS S3\n\nimport os\nimport json\nimport logging\nfrom datetime import datetime, timedelta, timezone\n\nimport boto3\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\n\ndef lambda_handler(event: dict, context: dict) -> bool:\n\n  '''\n  Diariamente é executado para compactar as diversas mensagensm, no formato\n  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único \n  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n  '''\n\n  # vars de ambiente\n\n  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n\n  # vars lógicas\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n  # código principal\n\n  table = None\n  client = boto3.client('s3')\n\n  try:\n\n      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n\n      for content in response['Contents']:\n\n        key = content['Key']\n        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n\n        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n\n          data = json.load(fp)\n          data = data[\"message\"]\n\n        parsed_data = parse_data(data=data)\n        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n\n        if table:\n\n          table = pa.concat_tables([table, iter_table])\n\n        else:\n\n          table = iter_table\n          iter_table = None\n          \n      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n\n      return True\n  \n  except Exception as exc:\n      logging.error(msg=exc)\n      return False\n    \n\n# data wrangling\n\ndef parse_data(data: dict) -> dict:\n\n  date = datetime.now().strftime('%Y-%m-%d')\n  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n  parsed_data = dict()\n\n  for key, value in data.items():\n\n      if key == 'from':\n          for k, v in data[key].items():\n              if k in ['id', 'is_bot', 'first_name']:\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n      elif key == 'chat':\n          for k, v in data[key].items():\n              if k in ['id', 'type']:\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n      elif key in ['message_id', 'date', 'text']:\n          parsed_data[key] = [value]\n\n  if not 'text' in parsed_data.keys():\n    parsed_data['text'] = [None]\n\n  return parsed_data\n```\n\n**2.3.** `AWS EventBridge` para acionar a função `AWS Lambda` criada para transformar o JSON do dia anterior e armazenar o PARQUET no `AWS S3 bucket` sufixo `-enriched` todos os dias 00h (GMT-3) em \"Criar regra > Nome, Programação > Continuar a criar regra > cron(0 3 * * ? *) > Próximo > Serviço AWS, Função do Lambda, Função (sufixo `-enriched`) > Próximo (x2) > Criar regra\";","metadata":{}},{"cell_type":"markdown","source":"## 3/3\\. Apresentação\n\n**3.1.** Tabela com os dados enriquecidos utilizando SQL no `AWS Athena`;\n\n```sql\n# Consulta SQL para criar tabela com os dados enriqeucidos particionados por dia:\n\nCREATE EXTERNAL TABLE `telegram`(\n  `message_id` bigint, \n  `user_id` bigint, \n  `user_is_bot` boolean, \n  `user_first_name` string, \n  `chat_id` bigint, \n  `chat_type` string, \n  `text` string, \n  `date` bigint)\nPARTITIONED BY ( \n  `context_date` date)\nROW FORMAT SERDE \n  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' \nSTORED AS INPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat' \nOUTPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\nLOCATION\n  's3://<bucket-enriquecido>/<pasta-particionada>'\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-create-table.png?raw=true)\n\n**3.2.** Carrega as partições na tabela criada;\n\n```sql\nMSCK REPAIR TABLE `telegram`;\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-repair-table.png?raw=true)\n\n3.2.1. Para atualizar a tabela também é possível utilizar o comando a seguir para reduzir possíveis custos de consulta;\n ```sql\n ALTER TABLE <nome-tabela> ADD PARTITION <coluna-partição> = <valor-partição>\n  ```\n\n**3.3.** Dados analíticos;\n\n- Quantidade de mensagens por dia;\n\n```sql\nSELECT \n  context_date, \n  count(1) AS \"message_amount\" \nFROM \"telegram\" \nGROUP BY context_date \nORDER BY context_date DESC\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-select-message_amount.png?raw=true)\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/graph-select-message_amount.png?raw=true)\n\n- Quantidade de mensagens por usuário por dia.\n\n```sql\nSELECT \n  user_id, \n  user_first_name, \n  context_date, \n  count(1) AS \"message_amount\" \nFROM \"telegram\" \nGROUP BY \n  user_id, \n  user_first_name, \n  context_date \nORDER BY context_date DESC\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-select-user-message_amount.png?raw=true)\n\n- Média do tamanho das mensagens por usuário por dia.\n\n```sql\nSELECT \n  user_id, \n  user_first_name, \n  context_date,\n  CAST(AVG(length(text)) AS INT) AS \"average_message_length\" \nFROM \"telegram\" \nGROUP BY \n  user_id, \n  user_first_name, \n  context_date \nORDER BY context_date DESC\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-select-user-message_lenght.png?raw=true)\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/graph-select-user-message_lenght.png?raw=true)\n\n- Quantidade de mensagens por hora por dia da semana por número da semana.\n\n```sql\nWITH \nparsed_date_cte AS (\n    SELECT \n        *, \n        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n    FROM \"telegram\" \n),\nhour_week_cte AS (\n    SELECT\n        *,\n        EXTRACT(hour FROM parsed_date) AS parsed_date_hour,\n        EXTRACT(dow FROM parsed_date) AS parsed_date_weekday,\n        EXTRACT(week FROM parsed_date) AS parsed_date_weeknum\n    FROM parsed_date_cte\n)\nSELECT\n    parsed_date_hour,\n    parsed_date_weekday,\n    parsed_date_weeknum,\n    count(1) AS \"message_amount\" \nFROM hour_week_cte\nGROUP BY\n    parsed_date_hour,\n    parsed_date_weekday,\n    parsed_date_weeknum\nORDER BY\n    parsed_date_weeknum,\n    parsed_date_weekday\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-select-hour-week-message_amount.png?raw=true)\n\n-  Total de vezes que cada palavra única aparece em todas as mensagens\n\n```sql\nWITH words AS (\n  SELECT word\n  FROM \"telegram\",\n  UNNEST(split(\"text\", ' ')) AS t(word)\n)\nSELECT word, COUNT(*) as count\nFROM words\nGROUP BY word\nORDER BY count DESC;\n```\n\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/athena-select-count-unnest-words.png?raw=true)\n![](https://github.com/rafie-b/Data-Warehouse-AWS-Pipeline-Chat-API/blob/main/repo-Data-Warehouse-AWS-Pipeline-Chat-API/graph-select-count-unnest-words.png?raw=true)","metadata":{}}]}